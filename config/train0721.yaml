# 在初始目录运行：python main.py --config config/train.yaml
# 实现：
# 1. 每个trajectory都补足至或者随机采样至100帧
# 2. 21个连续数据表示关节+1个离散数据表示是否抓取=22 按照RT-1原文进行tokenization至256 bins
# 3. RGBD数据是在feeder中在线获取，这里没有实现RT-1原文的“历史6帧”，而是只取了当前1帧
# 4. 由于服务器单卡的显存限制，设置了n_forward控制小批次的前向和反向，避免OOM

seed: 1 # 固定所有的随机种子
work_dir: /data2/maliang/zhangkaidong/IL/rt-1-IL/work_dir/rl072323 # 这个修改为希望存模型/存log的路径
run_mode: train

# feeder
feeder: feeders.feeder_rl.Feeder
train_feeder_args:
  data_path: /data2/maliang/zhangkaidong/IL/rt-1-IL/RLexpert/0718_single_merge_data.txt # 这个修改为csv VRdata 训练集路径
  channel_name: localhost:30003
  sceneID: 0
  sample_frame: 20
  bin: 50

test_feeder_args:
  data_path: /data2/maliang/zhangkaidong/IL/rt-1-IL/RLexpert/0718_single_merge_data.txt # 这个修改为csv VRdata 测试集路径
  channel_name: localhost:30003
  sceneID: 0
  sample_frame: 20
  bin: 50

# model
model: Model.RT1.RT1_state
model_args:
  action_nums: 7
  bins: 50

#optim
optimizer: AdamW
weight_decay: 0.0004
base_lr: 3.e-4  #continuous: 1e-3
lr_decay_rate: 0.1
step: [15, 25]
warm_up_epoch: 5
nesterov: True

# loss
# loss: CrossEntropy
loss: MSELoss

# training
device: [0]
cuda_visible_device: '0'
batch_size: 1
test_batch_size: 1
num_epoch: 30
eval_interval: 1 # eval的epoch间隔
n_forward: 5 # 每张GPU上的batchsize*sample_frame 须被 n_forward整除
save_epoch: 1 # the start epoch to save model
